---
title: "DATA420_KNN_GermanCredit"
author: "Jason Pemberton"
date: "2023-11-13"
output:
    html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Libraries
```{r}
library(tidyverse)
library(caret)
library(class)
library(corrplot)

gc <- read.csv("data/german_credit.csv")
str(gc)

# The variable "Creditability" is our target or dependent variable

gc.subset <- gc[c('Creditability','Age..years.','Sex...Marital.Status','Occupation','Account.Balance','Credit.Amount','Length.of.current.employment','Purpose')]
head(gc.subset)

# Create a function to normalize our data to ensure large data ranges do not dominate our model

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) } # creating a normalize function for easy conversion.

gc.subset.n<- as.data.frame(lapply(gc.subset[,2:8], normalize)) # lapply creates list that is why it is converted to dataframe and it applies defined function (which is 'normalize') to all the list values which is here column 2 to 8 as first column is target/response.
head(gc.subset.n)

#Now all attributes having value in the range 0 to 1 which is normalized data and 'Creditability' column has been removed as sample value starts form column 2.

#Creating Training and Test data set. Training data will be used to build model whereas test data will be used for validation and optimization of model by tuning k value.

set.seed(123)  # To get the same random sample
dat.d <- sample(1:nrow(gc.subset.n),size=nrow(gc.subset.n)*0.7,replace = FALSE) #random selection of 70% data.

train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[-dat.d,] # remaining 30% test data

#Now creating separate dataframe for 'Creditability' feature which is our target.
train.gc_labels <- gc.subset[dat.d,1]
test.gc_labels  <- gc.subset[-dat.d,1]  


knn.26 <-  knn(train=train.gc, test=test.gc, cl=train.gc_labels, k=26)


## Let's calculate the proportion of correct classification for k = 26

ACC.26 <- 100 * sum(test.gc_labels == knn.26)/NROW(test.gc_labels)  # For knn = 26

ACC.26    #Accuracy is 67.67%


table(knn.26 ,test.gc_labels) 



# Predict on the test data
predictions.26 <- as.factor(knn.26)


# Evaluate the model
confusion_matrix.26 <- table(Actual = test.gc$Creditability, Predicted = predictions.26)
print(confusion_matrix.26)


# For kNN algorithm, the tuning parameters are ‘k’ value and number of ’features/attributes selection.
# Optimum ‘k’ value can be found using ‘elbow’ or ‘maximum % accuracy’ graph but ‘feature selection’ can be done only through understanding of features in kNN algorithm.
i=1                          # declaration to initiate for loop
k.optm=1                     # declaration to initiate for loop
for (i in 1:28){ 
  knn.mod <-  knn(train=train.gc, test=test.gc, cl=train.gc_labels, k=i)
  k.optm[i] <- 100 * sum(test.gc_labels == knn.mod)/NROW(test.gc_labels)
  k=i  
  cat(k,'=',k.optm[i],'\n')       # to print % accuracy 
}


max_accuracy_index <- which.max(k.optm)
max_accuracy <- k.optm[max_accuracy_index]
optimal_k <- max_accuracy_index

# Plotting the accuracy graph
plot(k.optm, type="b", xlab="K-Value", ylab="Accuracy level")

# Add a red dot at the maximum accuracy point
points(optimal_k, max_accuracy, col="red", pch=19)

# Label the maximum accuracy and associated K
text(optimal_k, max_accuracy, sprintf("  Max Accuracy\n  K=%d\n  Accuracy=%.2f%%", optimal_k, max_accuracy), pos=1, col="red")

# At k=25, maximum accuracy achieved which is 68%, after that, it seems increasing K increases the classification but reduces success rate. 
# It is worse to class a customer as good when it is bad, than it is to class a customer as bad when it is good.
# Further accuracy can be increased by optimizing feature selections and repeating the above mentioned algorithm.
```

# Load & Prepare Data
```{r}

```

# Partition Data
```{r}

```

# KNN Model
```{r}


```

# Plot Model Results
```{r}


```

