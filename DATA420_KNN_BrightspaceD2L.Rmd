---
title: "DATA420_KNN_BrightspaceD2L"
author: "Jason Pemberton"
date: "2023-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Libraries, include=FALSE}
library(class) # Load the class library to gain access to the knn function
library(tidyverse) # Load tidyverse for ggplot and working with dataframes
```

Create sample dataframe with two columns of continuous data (scatterplot) and a third column of categorical data (labels)
```{r Create and visualize dataframe}

data <- data.frame(
  x1 = c(1, 2, 3, 4, 5, 6, 3, 3, 5, 6),
  x2 = c(2, 3, 1, 6, 5, 4, 4, 6, 4, 6),
  labels = c("A", "A", "A", "B", "B", "B", "A", "B", "B", "B")
)

# Plot the data using ggplot - use geom_text to control the labels of the data points
data_plot <- data %>% 
  ggplot(aes(x1, x2)) +
  geom_point(size = 3) +
  geom_text(aes(label = labels), hjust = -0.5, vjust = -0.5)

data_plot
```


Ideally you should not test your knn model on 100% of your data. You should withhold a portion of your data 
from the model (test) by splitting your data into training and testing data frames. There are many ways to do 
this in R. Start with 70% training and 30% testing and adjust to see the impact on your model accuracy

Split the data into training and testing sets
```{r data partition}
train_data <- data[c(1:7), 1:2] # first 7 rows of columns 1 & 2 of dataframe
test_data <- data[c(8:10), 1:2] # last 3 rows of columns 1 & 2 of dataframe

# Split the labels accordingly
train_labels <- data[c(1:7), 3] # first 7 rows of columns 3 of dataframe
test_labels <- data[c(8:10), 3] # last 3 rows of columns 3 of dataframe
```


Perform KNN classification. Start with k=3, but try other values to test model accuracy
```{r knn model}
k <- 3  # Number of neighbors. Try different values to see the impact on your model accuracy
knn_result <- knn(train_data, test_data, cl = train_labels, k = k)

# Convert factors to characters
actual_labels <- as.character(test_labels)
knn_result <- as.character(knn_result)

# Confusion Matrix
conf_matrix <- table(Actual = actual_labels, Predicted = knn_result, dnn = c("Actual", "Predicted"))
print("Confusion Matrix:")
print(conf_matrix)

# Model Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Model Accuracy:", round(accuracy, 2)))
```

This model achieved 100% accuracy in predicting which label to apply to the test data that was withheld during the training phase. 
While this is unlikely for data in the "real" world, it is perfect to test the model on new unlabeled data. We will create a new 
dataframe and test the model on data it has not seen before
```{r Testing model, warning=FALSE}
# New unlabeled data point for classification
new_data <- data.frame(x1 = c(2.5, 2.5, 2, 4, 3.5, 5),
                       x2 = c(3, 4, 2, 5, 5, 2))

# Predict labels for new data using the knn model generated above
predicted_labels <- knn(train_data, new_data, cl = train_labels, k = k, prob = FALSE)

# Display the predicted labels
print("Predicted Labels for New Data:")
print(predicted_labels)

# Add the new points to the original plot - don't add labels yet
data_plot +
  geom_point(data = new_data, aes(x = x1, y = x2)) +
  geom_text(data = new_data, aes(x = x1, y = x2, label=NA))


# Add the new points with the KNN predicted labels to the original plot
data_plot +
  geom_point(data = new_data, aes(x = x1, y = x2, color = predicted_labels), size = 3) +
  geom_text(data = new_data, aes(x = x1, y = x2, label = predicted_labels), hjust = -0.5, vjust = -0.5)
```

Optional: wrap the knn model function in a for loop and test a range of k values output the k values and their corresponding 
accuracy results to a dataframe and visualize the results with a line plot to determine optimal k (code below has been set to 
"do not run" and will not show up when the file is knit)

```{r Test multiple k values, eval=FALSE, include=FALSE}
# Create an empty data frame to store results
results_df <- data.frame(k = numeric(), accuracy = numeric())

# Specify the range of k values
k_values <- 1:10

# Iterate over different values of k
for (k in k_values) {
  # Perform KNN classification
  knn_result <- knn(train_data, test_data, cl = train_labels, k = k)

# Convert factors to characters
  actual_labels <- as.character(test_labels)
  knn_result <- as.character(knn_result)

# Confusion Matrix
  conf_matrix <- table(Actual = actual_labels, Predicted = knn_result, dnn = c("Actual", "Predicted"))

# Model Accuracy
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

# Store results in the data frame
  results_df <- rbind(results_df, data.frame(k = k, accuracy = accuracy))
}

# Print the results data frame
print(results_df)

# plotting accuracy vs. k
ggplot(results_df, aes(x = k, y = accuracy)) +
  geom_line() +
  labs(title = "Accuracy vs. k",
        x = "k",
        y = "Accuracy") +
  theme_minimal()

```

